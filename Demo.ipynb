{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49047ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done data_processing/processed/filtered_encoder_data.csv\n"
     ]
    }
   ],
   "source": [
    "from data_processing.preprocess_encoder_data import filter_and_dedup_encoder_data\n",
    "\n",
    "filter_and_dedup_encoder_data(\n",
    "    encoder_csv_path='data_processing/raw/encoder_data.csv',\n",
    "    stroke_map_ty_path='data_processing/mapping/stroke_mapping_name.csv',\n",
    "    hit_area_map_path='data_processing/mapping/hit_area_mapping.csv',\n",
    "    stroke_map_llm_path='data_processing/mapping/stroke_mapping_llm.csv',\n",
    "    output_csv_path='data_processing/processed/filtered_encoder_data.csv',\n",
    "    dedup_keep='last',       \n",
    "    sort_by=None             \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2c28bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   0%|          | 26/15838 [00:05<57:23,  4.59it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset_pipeline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo_cropper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VideoCropper\n\u001b[1;32m      3\u001b[0m cropper \u001b[38;5;241m=\u001b[39m VideoCropper(output_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput\u001b[39m\u001b[38;5;124m'\u001b[39m,video_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset/Video\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mcropper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrop_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata_processing/processed/filtered_encoder_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/HDD2/aiden/PrecisionSportDataset/dataset_pipeline/video_cropper.py:48\u001b[0m, in \u001b[0;36mVideoCropper.crop_videos\u001b[0;34m(self, csv_path)\u001b[0m\n\u001b[1;32m     45\u001b[0m fps \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mget(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_FPS)\n\u001b[1;32m     46\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_crop_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/HDD2/aiden/PrecisionSportDataset/dataset_pipeline/video_cropper.py:31\u001b[0m, in \u001b[0;36mVideoCropper._crop_video\u001b[0;34m(self, video_path, start_frame, end_frame, output_path, fps)\u001b[0m\n\u001b[1;32m     28\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwrite(img)\n\u001b[1;32m     29\u001b[0m     frame \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 31\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelease\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dataset_pipeline.video_cropper import VideoCropper\n",
    "\n",
    "cropper = VideoCropper(output_path='Output',video_dir='Dataset/Video')\n",
    "cropper.crop_videos('data_processing/processed/filtered_encoder_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e5bac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating captions: 100%|██████████| 15838/15838 [00:00<00:00, 34973.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption Json generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dataset_pipeline.caption_generator import CaptionGenerator\n",
    "csv_path = 'data_processing/processed/filtered_encoder_data.csv'\n",
    "caption_output_dir = 'generated_labels/caption'\n",
    "os.makedirs(caption_output_dir, exist_ok=True)\n",
    "\n",
    "caption_gen = CaptionGenerator(caption_output_dir)\n",
    "caption_df = caption_gen.generate_captions(csv_path)\n",
    "caption_csv = os.path.join(caption_output_dir, 'dataset_labels_caption.csv')\n",
    "caption_df.to_csv(caption_csv, index=False)\n",
    "print(f'Captions saved to: {caption_csv}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d819452e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QA by stroke-chunk: 100%|██████████| 1667/1667 [00:11<00:00, 139.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split complete: Total 54138, Train 44123, Val 10015, Moved 527\n"
     ]
    }
   ],
   "source": [
    "from dataset_pipeline.qa_generator import QAGenerator\n",
    "csv_path = 'data_processing/processed/filtered_encoder_data.csv'\n",
    "caption_output_dir = 'generated_labels/caption'\n",
    "qa_output_dir = 'generated_labels/QA'\n",
    "os.makedirs(qa_output_dir, exist_ok=True)\n",
    "qa_output_path = os.path.join(qa_output_dir, 'qa_dataset.json')\n",
    "\n",
    "templates_all = [\"When does the {player} hits a {stroke} {hit_area}?\"]\n",
    "templates_ps  = [\"When does the {player} hits a {stroke}?\"]\n",
    "templates_s   = [\"When is a {stroke} hits?\"]\n",
    "templates_h   = [\"Which stroke is hit {hit_area}?\"]\n",
    "\n",
    "qa_gen = QAGenerator(\n",
    "    templates_with_all=templates_all,\n",
    "    templates_player_stroke=templates_ps,\n",
    "    templates_stroke_only=templates_s,\n",
    "    templates_hit_area_only=templates_h,\n",
    "    stroke_chunk_size=5,\n",
    "    caption_csv_path=caption_csv\n",
    ")\n",
    "qa_gen.generate_by_rally(\n",
    "    csv_path=csv_path,\n",
    "    output_path=qa_output_path,\n",
    "    num_questions_per_rally=14,\n",
    "    val_to_train_ratio=0.05\n",
    ")\n",
    "print(f'QA dataset saved to: {qa_output_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
